{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau"
      ],
      "metadata": {
        "id": "4NvRIjQCtml3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls7ZBQ8Stwwq",
        "outputId": "845312f0-2d39-4e21-8163-d11949e1c213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/Dataset/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Dataset/test.csv')\n",
        "\n",
        "\n",
        "print(train_df.head())\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "HQh_meLMtmi8",
        "outputId": "5ac7fb69-a456-4634-e647-09267dc4b808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          ID     label    0    1    2    3    4    5    6    7  ...  1014  \\\n",
            "0  TRAIN_000  building  251  196   51   63   68   78  189   34  ...    85   \n",
            "1  TRAIN_001  building  247  184  203  237  255  255  193  255  ...   242   \n",
            "2  TRAIN_002  building  217  223  232  231  239  212  109  115  ...    96   \n",
            "3  TRAIN_003       cat  133  149  153  138   68  157  159  166  ...   245   \n",
            "4  TRAIN_004  building  240  213  187  159  112  134  239  233  ...   148   \n",
            "\n",
            "   1015  1016  1017  1018  1019  1020  1021  1022  1023  \n",
            "0   195    63    30    73    65    63   201   251   248  \n",
            "1   239   241   242   242   241   241   241   240   238  \n",
            "2    90   103   166   191   163   190   190   206   231  \n",
            "3   241   247   255   250   190   186   244   254   201  \n",
            "4    59   163   133    92   196   221   194   182   251  \n",
            "\n",
            "[5 rows x 1026 columns]\n",
            "         ID    0    1    2    3    4    5    6    7    8  ...  1014  1015  \\\n",
            "0  TEST_000  186  189  189  190  190  190  192  191  192  ...   200   200   \n",
            "1  TEST_001  209  219  227  227  220  218  225  225  225  ...    61   103   \n",
            "2  TEST_002   52  232  249  209  117   63   50   70   23  ...   115   112   \n",
            "3  TEST_003  239  230  204  222  194  198  228  235  198  ...   202   170   \n",
            "4  TEST_004  247  247  248  247  246  246  245  246  245  ...   148   133   \n",
            "\n",
            "   1016  1017  1018  1019  1020  1021  1022  1023  \n",
            "0   199   197   197   194   193   191   192   193  \n",
            "1   134   143   236   220   219   219   219   214  \n",
            "2   148   173    50    20   212   251   246   249  \n",
            "3   165   178   145   175   234   197   226   238  \n",
            "4   212   243   230   232   233   234   234   234  \n",
            "\n",
            "[5 rows x 1025 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "\n",
        "train_df['label'] = label_encoder.fit_transform(train_df['label'])\n",
        "\n",
        "\n",
        "print(train_df['label'].head())\n",
        "\n",
        "\n",
        "print(f\"Data type of label: {type(train_df['label'].iloc[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqZ7c01HuN0C",
        "outputId": "a6df76cf-be8b-4796-a9d1-5ce401cfd86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    4\n",
            "1    4\n",
            "2    4\n",
            "3    5\n",
            "4    4\n",
            "Name: label, dtype: int64\n",
            "Data type of label: <class 'numpy.int64'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class IconDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None, has_label=True):\n",
        "        self.data = dataframe\n",
        "        self.transform = transform\n",
        "        self.has_label = has_label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img = self.data.iloc[idx, 1:].values.astype(np.uint8)\n",
        "        img = img[:1024]\n",
        "        img = img.reshape(32, 32)\n",
        "\n",
        "\n",
        "        if self.has_label:\n",
        "            label = self.data.iloc[idx]['label']\n",
        "        else:\n",
        "            label = None\n",
        "\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "\n",
        "        img = torch.tensor(img, dtype=torch.float32)\n",
        "\n",
        "        if self.has_label:\n",
        "            label = torch.tensor(label, dtype=torch.long)\n",
        "            return img, label\n",
        "        else:\n",
        "            return img"
      ],
      "metadata": {
        "id": "D-vp-ZEPuM21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = train_test_split(\n",
        "    train_df,\n",
        "    test_size=0.2,\n",
        "    stratify=train_df['label']\n",
        ")\n",
        "\n",
        "\n",
        "train_dataset = IconDataset(train_data)\n",
        "val_dataset = IconDataset(val_data)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "\n",
        "test_dataset = IconDataset(test_df, has_label=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
      ],
      "metadata": {
        "id": "LmwPmNFAtmdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "\n",
        "        self.downsample = None\n",
        "        if in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(residual)\n",
        "        out += residual\n",
        "        out = torch.relu(out)\n",
        "        return out\n",
        "\n",
        "class InceptionBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_pool):\n",
        "        super(InceptionBlock, self).__init__()\n",
        "        self.branch1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n",
        "\n",
        "        self.branch2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, red_3x3, kernel_size=1),\n",
        "            nn.Conv2d(red_3x3, out_3x3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        self.branch3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, red_5x5, kernel_size=1),\n",
        "            nn.Conv2d(red_5x5, out_5x5, kernel_size=5, padding=2)\n",
        "        )\n",
        "\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, out_pool, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out1 = torch.relu(self.branch1(x))\n",
        "        out2 = torch.relu(self.branch2(x))\n",
        "        out3 = torch.relu(self.branch3(x))\n",
        "        out4 = torch.relu(self.branch4(x))\n",
        "\n",
        "        out = torch.cat([out1, out2, out3, out4], dim=1)\n",
        "        return out\n",
        "\n",
        "class IconCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IconCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "\n",
        "        self.block1 = ResidualBlock(32, 32)\n",
        "        self.inception_block = InceptionBlock(32, 32, 32, 64, 16, 32, 32)\n",
        "        self.block2 = ResidualBlock(160, 64)\n",
        "        self.block3 = ResidualBlock(64, 128)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(128 * 2 * 2, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.block1(x)\n",
        "        x = self.inception_block(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = x.view(-1, 128 * 2 * 2)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "8l7sePpMtma2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = IconCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDOYmEDTtg5a",
        "outputId": "9324c999-e489-4380-bf2a-b58b90b66850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9CKAkRcvNYQ",
        "outputId": "05d09888-41f9-4830-8b07-cacf352323ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IconCNN(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (block1): ResidualBlock(\n",
              "    (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (inception_block): InceptionBlock(\n",
              "    (branch1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "    (branch2): Sequential(\n",
              "      (0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "    (branch3): Sequential(\n",
              "      (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    )\n",
              "    (branch4): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
              "      (1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (block2): ResidualBlock(\n",
              "    (conv1): Conv2d(160, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (downsample): Sequential(\n",
              "      (0): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (block3): ResidualBlock(\n",
              "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (downsample): Sequential(\n",
              "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_counter = 0\n",
        "best_val_accuracy = 0.0"
      ],
      "metadata": {
        "id": "NV2U7wj00Gh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=40):\n",
        "    global early_stopping_counter, best_val_accuracy\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for data in tqdm(train_loader):\n",
        "            images, labels = data\n",
        "            images = images.unsqueeze(1).float().to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "\n",
        "        val_accuracy = evaluate_model(model, val_loader)\n",
        "\n",
        "\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            early_stopping_counter = 0\n",
        "        else:\n",
        "            early_stopping_counter += 1\n",
        "\n",
        "        if early_stopping_counter >= 5:\n",
        "            print(\"Early stopping triggered. Training will stop.\")\n",
        "            break\n",
        "\n",
        "\n",
        "        scheduler.step(running_loss)\n",
        "\n",
        "\n",
        "def evaluate_model(model, val_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in val_loader:\n",
        "            images, labels = data[0], data[1]\n",
        "            images, labels = images.unsqueeze(1).float().to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    val_accuracy = 100 * correct / total\n",
        "    print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n",
        "    return val_accuracy\n",
        "\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer, scheduler, num_epochs=30)\n",
        "\n",
        "\n",
        "evaluate_model(model, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiJu-bZRtg2t",
        "outputId": "351a4ff3-b38b-462e-842e-d6a8cc389648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 21.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Loss: 1.6872, Accuracy: 42.28%\n",
            "Validation Accuracy: 55.84%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 21.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/30], Loss: 0.7497, Accuracy: 74.47%\n",
            "Validation Accuracy: 61.04%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 21.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/30], Loss: 0.4105, Accuracy: 86.18%\n",
            "Validation Accuracy: 87.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:02<00:00, 18.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/30], Loss: 0.2716, Accuracy: 90.73%\n",
            "Validation Accuracy: 74.03%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 21.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/30], Loss: 0.2333, Accuracy: 92.36%\n",
            "Validation Accuracy: 81.82%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 21.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/30], Loss: 0.1314, Accuracy: 95.93%\n",
            "Validation Accuracy: 91.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 21.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/30], Loss: 0.0714, Accuracy: 98.37%\n",
            "Validation Accuracy: 87.01%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 21.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/30], Loss: 0.0234, Accuracy: 99.67%\n",
            "Validation Accuracy: 90.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 19.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/30], Loss: 0.0195, Accuracy: 99.67%\n",
            "Validation Accuracy: 85.71%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 20.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/30], Loss: 0.0091, Accuracy: 100.00%\n",
            "Validation Accuracy: 92.86%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 21.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [11/30], Loss: 0.0074, Accuracy: 99.67%\n",
            "Validation Accuracy: 91.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 21.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [12/30], Loss: 0.0036, Accuracy: 100.00%\n",
            "Validation Accuracy: 92.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 21.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [13/30], Loss: 0.0017, Accuracy: 100.00%\n",
            "Validation Accuracy: 91.56%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:01<00:00, 21.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [14/30], Loss: 0.0008, Accuracy: 100.00%\n",
            "Validation Accuracy: 92.21%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 39/39 [00:02<00:00, 18.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [15/30], Loss: 0.0005, Accuracy: 100.00%\n",
            "Validation Accuracy: 92.86%\n",
            "Early stopping triggered. Training will stop.\n",
            "Validation Accuracy: 92.86%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92.85714285714286"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_submission(model, test_loader, test_df, output_file='submission.csv'):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader):\n",
        "            images = data.unsqueeze(1).float().to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "\n",
        "    predicted_labels = label_encoder.inverse_transform(predictions)\n",
        "\n",
        "\n",
        "    submission_df = pd.DataFrame({\n",
        "        'ID': test_df['ID'],\n",
        "        'label': predicted_labels\n",
        "    })\n",
        "\n",
        "\n",
        "    submission_df.to_csv(output_file, index=False)\n",
        "    print(f'Submission file saved to {output_file}')\n",
        "\n",
        "\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Dataset/test.csv')\n",
        "generate_submission(model, test_loader, test_df, output_file='/content/drive/MyDrive/Dataset/submission.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIRr8suztgvN",
        "outputId": "b230f3e5-88e5-47b3-a7a6-b581f6b82578"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 44.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submission file saved to /content/drive/MyDrive/Dataset/submission.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OWdwRVGc5dyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C_bcqGDBtgsw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}